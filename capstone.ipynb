{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnaLyrics Engine: Predicting Music Genres with NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genre Playlists\n",
    "- https://everynoise.com/engenremap.html\n",
    "\n",
    "Spotify Metadata\n",
    "- https://developer.spotify.com/documentation/web-api\n",
    "- https://spotipy.readthedocs.io/en/2.22.1/\n",
    "\n",
    "Genius Lyrics\n",
    "- https://docs.genius.com\n",
    "- https://lyricsgenius.readthedocs.io/en/master/reference/genius.html\n",
    "\n",
    "Modeling\n",
    "\n",
    "- https://www.kaggle.com/code/nilaychauhan/getting-started-with-nlp-pipelines\n",
    "    - Extracting plain text / Reducing complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate lemmatizer\n",
    "lemmer = WordNetLemmatizer()\n",
    "\n",
    "# custom stopwords list\n",
    "sw = set(stopwords.words('english'))\n",
    "custom_sw = [\"i'd\", \"i'm\",\n",
    "             'yeah', 'ah', 'oh']\n",
    "sw.update(custom_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(lyrics):\n",
    "    # remove numbers and special characters\n",
    "    lyrics = re.sub(r'[^a-zA-Z\\s]', '', lyrics)\n",
    "    # remove extra spaces and new lines\n",
    "    lyrics = re.sub(r'\\s+|\\n\\s*\\n', ' ', lyrics)\n",
    "    # lowercase all\n",
    "    lyrics = lyrics.lower()\n",
    "\n",
    "    # tokenize, lemmatize, remove stopwords\n",
    "    tokens = word_tokenize(lyrics)\n",
    "    tokens = [lemmer.lemmatize(word) for word in tokens]\n",
    "    tokens = ' '.join([word for word in tokens if word not in sw])\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['lyrics_text'].apply(preprocess_text)\n",
    "df['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tuning and final model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables for modeling\n",
    "X = df['tokens']\n",
    "y = df['genre']\n",
    "\n",
    "# split holdout set for final model validation\n",
    "X_df, X_hold, y_df, y_hold = train_test_split(X, y, test_size=0.2, random_state=95)\n",
    "y_df.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_model(model, X, y):\n",
    "    genres = ['pop', 'hip hop', 'rock', 'country']\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=95)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    pred = cross_val_predict(model, X, y)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y, pred))\n",
    "\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "    print(f\"Mean Accuracy: {cv_scores.mean():.2f}\")\n",
    "\n",
    "    accuracy = accuracy_score(y, pred)\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y, pred, normalize='true')\n",
    "\n",
    "    sns.heatmap(cm, xticklabels=genres, yticklabels=genres,\n",
    "                annot=True, fmt='.2f', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dummy classifier as baseline model\n",
    "baseline = DummyClassifier(strategy='uniform')\n",
    "analyze_model(baseline, X_df, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cv_mnb = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "analyze_model(pipe_cv_mnb, X_df, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tf_mnb = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "]) \n",
    "\n",
    "analyze_model(pipe_tf_mnb, X_df, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cv_rf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "analyze_model(pipe_cv_rf, X_df, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tf_rf = Pipeline([\n",
    "    ('vectorizer',TfidfVectorizer()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "analyze_model(pipe_tf_rf, X_df, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_cv_dt = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "analyze_model(pipe_cv_dt, X_df, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tf_dt = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "    ])\n",
    "\n",
    "analyze_model(pipe_tf_dt, X_df, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
